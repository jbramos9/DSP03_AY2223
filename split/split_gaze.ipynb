{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Gaze-Object Dataset Split"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"LpXHKkakultS"},"source":["## Imports\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"a9n0QM4QumsB"},"outputs":[],"source":["from json import dump, load, loads\n","from collections import Counter\n","from itertools import chain\n","from numpy.random import choice, seed\n","from math import log10\n","from itertools import product\n","from os import listdir\n","from os.path import join"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"pDxGlM9YvA1J"},"source":["## Inputs\n","This is the only part that must be changed between runs. Values here are the default."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"oZ-_d4wUvBM3"},"outputs":[],"source":["# Dataset Constants\n","PARTICIPANT_COUNT = 20\n","VIDEO_PER_PARTICIPANT = 50\n","\n","# Arbitrary but fixed number for random.shuffle\n","seed_number = 1234\n","\n","# Total fixed number of samples dedicated for training\n","train_size = 800 \n","\n","# Main source of annotation. Entire code is very format dependent\n","dataset_path = \"../dataset\"\n","\n","## Dataset Subdirectories (in Google Drive)\n","depth_dataset_path = f\"{dataset_path}/DEPTHS\"\n","video_dataset_path = f\"{dataset_path}/VIDEOS\"\n","\n","# Video-Intent-Gaze JSON source\n","label_filepath = f\"./intent_ann_new.json\"\n","\n","# Output Filepath\n","save_filepath = f\"./data/gaze_dataset.json\""]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TM5v185Wuwjx"},"source":["## Process\n","Prerequisite functions that describe the entire splitting process."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ln29il4542cC"},"source":["### Filepath Functions"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"KICkiAXS46OS"},"outputs":[],"source":["def participant_directories(format=\"\", root=\"\"):\n","    video_range = range(1, VIDEO_PER_PARTICIPANT + 1)\n","    participant_range = range(1, PARTICIPANT_COUNT + 1)\n","\n","    for participant, video in product(participant_range, video_range):\n","        directory =  join(\n","            root, \n","            f\"P{participant}/V{video}\", \n","            f\"P{participant}_V{video}.{format}\" if format else \"\")\n","        yield directory, participant, video"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"gfN9WoWQwwk_"},"outputs":[],"source":["def filename(root, participant, video, format=\"\"):\n","    return f\"{root}/P{participant}/V{video}/P{participant}_V{video}.{format}\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIQxf1KEJx8V"},"outputs":[],"source":["def format_filename(root, filepath):\n","    filename = filepath.split('.')[0]\n","    participant, video = filename.split('_')[:2]\n","    participant, video =int( participant[1:]), int(video[1:])\n","\n","    return f\"{root}/P{participant}/V{video}/{filepath}\""]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mrUMvd9yvmXy"},"source":["### Depth Inclusion"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"DvNOS-ZMxwzN"},"outputs":[],"source":["def depth_files(directory):\n","    return [format_filename(\"DEPTHS\", path) for path in listdir(directory)]"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"E5sm_dwSwzna"},"outputs":[],"source":["def video_depth_mapping():\n","    directories = participant_directories(\n","        root=depth_dataset_path)\n","\n","    return { filename(\"VIDEOS\", p, v, 'mp4'): depth_files(d)\n","            for d, p, v in directories }"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Xx2VDvNh0kjB"},"source":["### Bounding Box Inclusion"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"X5sdI8FsCB2p"},"outputs":[],"source":["def box_format(item):\n","    return [\n","        int(item[\"classifications\"] != []),\n","        item[\"bbox\"][\"top\"], \n","        item[\"bbox\"][\"left\"], \n","        item[\"bbox\"][\"width\"], \n","        item[\"bbox\"][\"height\"]\n","    ]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"DzLr_YZ297Cn"},"outputs":[],"source":["def bounding_boxes(label_filepath):\n","    with open(label_filepath) as labels:\n","        frames = [loads(label) for label in labels]\n","\n","    return [ { item[\"title\"]: box_format(item) \n","        for item in frame[\"objects\"] }\n","        for frame in frames ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U8h3QcQc2lml"},"outputs":[],"source":["def video_label_mapping():\n","    directories = participant_directories(\n","        root=video_dataset_path,\n","        format=\"ndjson\")\n","\n","    return {filename(\"VIDEOS\", p, v, 'mp4'): bounding_boxes(d) \n","        for d, p, v in directories}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qmxVo_WA0a8w"},"source":["### Splitting Mechanics"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A6RhhKBvuyNA"},"outputs":[],"source":["def weighted_object_dataset(label_filepath):\n","    with open(label_filepath) as dataset:\n","        dataset = load(dataset)\n","\n","    print(\"Loading Gaze Dataset\")\n","\n","    # Reformat video mapping into list of objects\n","    labels = dataset[\"hiphop\"][\"videos\"]\n","\n","    # Maps the list of PNG depth filepaths for a given video\n","    video_depth_map = video_depth_mapping()\n","    video_label_map = video_label_mapping()\n","\n","    # Sample Format\n","    samples = [\n","        {\n","            \"video\": format_filename(\"VIDEOS\", video),\n","            \"gaze_seq\": label[\"gaze_seq\"],\n","            \"bbox\": video_label_map[format_filename(\"VIDEOS\", video)],\n","            \"depth\": video_depth_map[format_filename(\"VIDEOS\", video)],\n","        }\n","        for video, label in labels.items()\n","    ]\n","\n","    return samples"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8FWE9UxeuzmB"},"outputs":[],"source":["def low_frequency_weighting(samples):\n","    print(\"Calculating weights\")\n","\n","    gaze_sequences = [sample[\"gaze_seq\"] for sample in samples]\n","    object_counter = Counter(chain.from_iterable(gaze_sequences))\n","    total = sum(1 / log10(count) for count in object_counter.values())\n","\n","    weight = {\n","        key: (1 / log10(count)) / (total * object_counter[key])\n","        for key, count in object_counter.items()\n","    }\n","    weights = [sum(weight[x] for x in gaze) for gaze in gaze_sequences]\n","\n","    return weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-aKtRVLu2HB"},"outputs":[],"source":["def split(samples, seed_number, train_size):\n","    seed(seed_number)\n","\n","    print(f\"Splitting Label Dataset (seed={seed_number})\")\n","\n","    weights = low_frequency_weighting(samples)\n","    \n","    training_set = choice(samples, size=train_size, p=weights, replace=False)\n","    training_set = list(training_set)\n","\n","    testing_set = [sample for sample in samples if sample not in training_set]\n","\n","    train_gazes = [sample[\"gaze_seq\"] for sample in training_set]\n","    test_gazes = [sample[\"gaze_seq\"] for sample in testing_set]\n","\n","    train_counter = Counter(chain.from_iterable(train_gazes))\n","    test_counter = Counter(chain.from_iterable(test_gazes))\n","\n","    total = sum(train_counter.values()) + sum(test_counter.values())\n","\n","    print(f\"Train | Test Split ({len(training_set)} | {len(testing_set)})\")\n","\n","    for object in train_counter:\n","        train_percent = train_counter[object]/total\n","        test_percent = test_counter[object]/total\n","        print(\n","            f\"\\t{train_percent:.5%}\\t|  {test_percent:.5%}\\t | {object}\"\n","        )\n","\n","    return training_set, testing_set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7miq7NZpu45D"},"outputs":[],"source":["def save_gaze_dataset(training_set, testing_set, save_path):\n","    # HIPHOP Gaze Dataset Format\n","    dataset = {\n","        \"hiphop\": {\n","            \"gaze\": {\n","                \"train\": training_set,\n","                \"test\": testing_set,\n","            }\n","        }\n","    }\n","\n","    # Save dataset\n","    with open(save_path, \"w\") as gaze_dataset:\n","        dump(dataset, gaze_dataset)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"g6FytmGJu6jY"},"source":["## Generate\n","\n","Run cell to generate a gaze split in json format. Note that any existing gaze split will be overwritten."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1951116,"status":"ok","timestamp":1683277112480,"user":{"displayName":"Matthew Antoni De Mesa","userId":"14499233318177830542"},"user_tz":-480},"id":"RiC7_c2ju7CL","outputId":"31d4666b-2b86-4dcd-c8a6-f2f5e0a655f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading Gaze Dataset\n","Splitting Label Dataset (seed=1234)\n","Calculating weights\n","Train | Test Split (800 | 200)\n","\t6.12351%\t|  1.58252%\t | Broom\n","\t6.90408%\t|  2.41266%\t | Pillow\n","\t6.84624%\t|  1.08579%\t | Book\n","\t3.78132%\t|  0.40146%\t | Cup\n","\t4.79373%\t|  0.58081%\t | Laptop\n","\t5.88049%\t|  0.47485%\t | Fruits\n","\t6.69994%\t|  1.34388%\t | Bottle\n","\t12.41567%\t|  8.68198%\t | none\n","\t3.01145%\t|  0.12248%\t | Sandwich\n","\t4.32179%\t|  0.66246%\t | Rug\n","\t5.53833%\t|  0.53366%\t | Racket\n","\t4.52252%\t|  1.02796%\t | Umbrella\n","\t2.84960%\t|  0.31057%\t | Bag\n","\t2.81995%\t|  0.14727%\t | Bowl\n","\t1.85956%\t|  0.03791%\t | Utensils\n","\t2.14534%\t|  0.08020%\t | Chair\n"]}],"source":["samples = weighted_object_dataset(label_filepath)\n","training_set, testing_set = split(samples, seed_number, train_size)\n","save_gaze_dataset(training_set, testing_set, save_filepath)"]}],"metadata":{"colab":{"collapsed_sections":["oIN3TiPxuhea","LpXHKkakultS","pDxGlM9YvA1J","ln29il4542cC","mrUMvd9yvmXy","Xx2VDvNh0kjB"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
