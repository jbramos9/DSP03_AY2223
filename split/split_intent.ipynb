{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["cVyzFZRpqxPW","mlYBJZzsqLgt","i1WPZigPtrXc","qc4Y-Yu-uCLZ"],"authorship_tag":"ABX9TyNRL71AIpScwiNygcFbGVCy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# HIPHOP Intention Dataset Split\n"],"metadata":{"id":"BExoZkHIuZV6"}},{"cell_type":"markdown","source":["## Connections\n","Connect to Google Drive and ensure dataset folder is present"],"metadata":{"id":"cVyzFZRpqxPW"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y0MsqcDup1NQ","executionInfo":{"status":"ok","timestamp":1686580433743,"user_tz":-480,"elapsed":20249,"user":{"displayName":"Stephen Singer","userId":"07833907350573086053"}},"outputId":"d1730d37-552b-4cde-ade4-2727c6ecca2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","/content/gdrive/Shareddrives/ECE 199 2s2223/Dataset\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","%cd \"/content/gdrive/Shareddrives/ECE 199 2s2223/Dataset/\""]},{"cell_type":"markdown","source":["## Imports\n"],"metadata":{"id":"mlYBJZzsqLgt"}},{"cell_type":"code","source":["from json import load, dump\n","from collections import defaultdict\n","from random import shuffle, seed"],"metadata":{"id":"4AGhLgiiqI4G","executionInfo":{"status":"ok","timestamp":1686580433744,"user_tz":-480,"elapsed":9,"user":{"displayName":"Stephen Singer","userId":"07833907350573086053"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Inputs\n","\n","This is the only part that must be changed between runs. Values here are the default."],"metadata":{"id":"i1WPZigPtrXc"}},{"cell_type":"code","source":["# Arbitrary but fixed number for random.shuffle\n","seed_number = 1234\n","\n","# Per Intention (100 samples * 8 intentions = 800 training samples)\n","train_size = 100 \n","\n","# Main source of annotation. Entire code is very format dependent\n","dataset_path = \"/content/gdrive/Shareddrives/ECE 199 2s2223/Dataset\"\n","label_filepath = f\"{dataset_path}/intent_ann_new.json\"\n","save_filepath = f\"{dataset_path}/Splits/intent_dataset.json\"\n","video_intent_filepath = f\"{dataset_path}/Splits/video_intent_map.json\""],"metadata":{"id":"DYhrU_6rql-k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Process\n","Prerequisite functions that describe the entire splitting process."],"metadata":{"id":"pI7fEtTDt1V6"}},{"cell_type":"code","source":["def intention_sorted_gazeseq(label_filepath):    \n","    with open(label_filepath) as dataset:\n","        dataset = load(dataset)\n","        labels = dataset[\"hiphop\"][\"videos\"]\n","\n","    # Group samples into a dictionary with intentions as keys and values \n","    # as list of samples with said intention\n","    samples = defaultdict(list)\n","\n","    for _, label in labels.items():\n","        samples[label[\"intent\"]].append(label[\"gaze_seq\"])\n","\n","    print(\"Grouping Label Dataset by Intention\")\n","\n","    label_items = sum(len(sequence) for sequence in samples.values())\n","\n","    print(f\"Label Set ({label_items} items)\")\n","    for intent, sequences in samples.items():\n","        items = len(sequences)\n","        print(f\"\\t{items} items ({items/label_items:2.2%}):\\t{intent}\")\n","\n","    return samples"],"metadata":{"id":"GBgKYvtDqPF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def split(samples, seed_number, train_size):\n","    seed(seed_number)\n","\n","    training_set = defaultdict(list)\n","    testing_set = defaultdict(list)\n","\n","    for intent in samples:\n","        shuffle(samples[intent])\n","        training_set[intent] = samples[intent][:train_size]\n","        testing_set[intent] = samples[intent][train_size:]\n","\n","    print(f\"Splitting Label Dataset (seed={seed_number})\")\n","\n","    train_items = sum(len(sequence) for sequence in training_set.values())\n","    test_items = sum(len(sequence) for sequence in testing_set.values())\n","\n","    print(f\"Training Set ({train_items} items)\")\n","    for intent, sequences in training_set.items():\n","        items = len(sequences)\n","        print(f\"\\t{items} items ({items/train_items:2.2%}):\\t{intent}\")\n","\n","    print(f\"Testing Set ({test_items} items)\")\n","    for intent, sequences in testing_set.items():\n","        items = len(sequences)\n","        print(f\"\\t{items} items  ({items/test_items:2.2%}):\\t{intent}\")\n","\n","    return training_set, testing_set"],"metadata":{"id":"sIS1tj48qXwl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_intention_dataset(training_set, testing_set, save_filepath):\n","    # HIPHOP Intention Dataset Format\n","    dataset = {\n","        \"hiphop\": {\n","            \"intentions\": {\n","                \"train\": training_set,\n","                \"test\": testing_set,\n","            }\n","        }\n","    }\n","\n","    # Save dataset\n","    with open(save_filepath, \"w\") as intention_dataset:\n","        dump(dataset, intention_dataset)"],"metadata":{"id":"xFQv19v-qcL2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generate\n","Run cell to generate an intention split in json format. Note that any existing intention split will be overwritten."],"metadata":{"id":"qc4Y-Yu-uCLZ"}},{"cell_type":"code","source":["samples = intention_sorted_gazeseq(label_filepath)\n","training_set, testing_set = split(samples, seed_number, train_size)\n","save_intention_dataset(training_set, testing_set, save_filepath)\n","\n","print(\"Finished\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ue8Fr4dmqg6D","executionInfo":{"status":"ok","timestamp":1681474359333,"user_tz":-480,"elapsed":1272,"user":{"displayName":"Stephen Singer","userId":"07833907350573086053"}},"outputId":"61e91d05-bfb2-4602-876d-9fda730f089d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Grouping Label Dataset by Intention\n","Label Set (1000 items)\n","\t127 items (12.70%):\tSpontaneous\n","\t120 items (12.00%):\tDrink\n","\t127 items (12.70%):\tStudy\n","\t115 items (11.50%):\tGo Outside\n","\t132 items (13.20%):\tEat\n","\t135 items (13.50%):\tIndeterminate\n","\t124 items (12.40%):\tClean the Area\n","\t120 items (12.00%):\tRest\n","Splitting Label Dataset (seed=1234)\n","Training Set (800 items)\n","\t100 items (12.50%):\tSpontaneous\n","\t100 items (12.50%):\tDrink\n","\t100 items (12.50%):\tStudy\n","\t100 items (12.50%):\tGo Outside\n","\t100 items (12.50%):\tEat\n","\t100 items (12.50%):\tIndeterminate\n","\t100 items (12.50%):\tClean the Area\n","\t100 items (12.50%):\tRest\n","Testing Set (200 items)\n","\t27 items  (13.50%):\tSpontaneous\n","\t20 items  (10.00%):\tDrink\n","\t27 items  (13.50%):\tStudy\n","\t15 items  (7.50%):\tGo Outside\n","\t32 items  (16.00%):\tEat\n","\t35 items  (17.50%):\tIndeterminate\n","\t24 items  (12.00%):\tClean the Area\n","\t20 items  (10.00%):\tRest\n","Finished\n"]}]},{"cell_type":"markdown","source":["## Miscellaneous"],"metadata":{"id":"1YwWqL8IduZ5"}},{"cell_type":"markdown","source":["### Intent-Video Mapping\n","\n","Generate mapping for video filename and intention\n"],"metadata":{"id":"ZsSPc6kwdw9Q"}},{"cell_type":"code","source":["# Read intention list\n","with open(label_filepath) as dataset:\n","    dataset = load(dataset)[\"hiphop\"][\"videos\"]\n","\n","# Build video filename to intention filemap\n","video_intent_map = {\n","    filename: contents[\"intent\"]\n","    for filename, contents in dataset.items()\n","}\n","\n","# Save mapping\n","with open(video_intent_filepath, \"w\") as video_intent_map_file:\n","    dump(video_intent_map, video_intent_map_file)"],"metadata":{"id":"3Tm7kkSQd3pZ"},"execution_count":null,"outputs":[]}]}