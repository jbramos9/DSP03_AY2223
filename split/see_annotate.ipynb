{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset Visualizer\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Run first to ensure suceeding code blocks function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "from PIL import ImageColor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotation Visualizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class loads the annotation details of a NDJSon for a given video, following the LabelBox Schema of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annotator:\n",
    "    \"\"\"Draws annotations on a video\n",
    "    based on a LabelBox ndjson annotation file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self._annotation = None\n",
    "        self._intent = None\n",
    "\n",
    "        self._video_output = None\n",
    "        self._video_capture = None\n",
    "\n",
    "        self._save_resolution = None\n",
    "        self._display_resolution = None\n",
    "\n",
    "    def load_video(\n",
    "        self,\n",
    "        video_filepath: str,\n",
    "        display_resolution: tuple[int],\n",
    "    ) -> None:\n",
    "        \"\"\"Initializes cv2.VideoCapture to read video for annotation.\n",
    "\n",
    "        Args:\n",
    "            video_filepath (str): Relative filepath of video to annotation.\n",
    "            display_resolution (tuple[int]): Video resolution during annotation\n",
    "        \"\"\"\n",
    "        self._video_capture = cv2.VideoCapture(video_filepath)\n",
    "        self._display_resolution = display_resolution\n",
    "\n",
    "    def load_annotation(self, annotation_filepath: str):\n",
    "        \"\"\"Loads ndjson file exported from LabelBox for video annotations.\n",
    "        The file contains the bounding boxes of objects detected in the video,\n",
    "        along with a label of focus (isGazed) on an object with respect to the\n",
    "        \"head\" object. This is project specific.\n",
    "\n",
    "        Args:\n",
    "            annotation_filepath (str): Relative filepath of ndjson file.\n",
    "        \"\"\"\n",
    "        with open(annotation_filepath) as file:\n",
    "            self._annotations = [json.loads(line) for line in file.readlines()]\n",
    "\n",
    "        self._intent = self._annotations[0][\"classifications\"][0][\"answer\"]\n",
    "        self._intent = self._intent[\"value\"]\n",
    "\n",
    "    def load_output_saver(\n",
    "        self, output_filepath: str, save_resolution: tuple[int]\n",
    "    ) -> None:\n",
    "        \"\"\"Initializes cv2.VideoWriter for mp4 reading to save annotated video.\n",
    "\n",
    "        Args:\n",
    "            output_filepath (str): Relative filepath for annotated video.\n",
    "            save_resolution (tuple[int]): Video resolution of annotated video.\n",
    "        \"\"\"\n",
    "        self._video_output = cv2.VideoWriter(\n",
    "            output_filepath, 0x7634706D, 30, save_resolution\n",
    "        )\n",
    "\n",
    "        self._save_resolution = save_resolution\n",
    "\n",
    "    def _draw_bounding_box(\n",
    "        self, object_name: str, bounding_box: tuple[float], color: str, frame\n",
    "    ) -> None:\n",
    "        \"\"\"Draws a rectangular outline on a frame.\n",
    "\n",
    "        Args:\n",
    "            object_name (str):\n",
    "            Label for bounding box\n",
    "\n",
    "            bounding_box (tuple[float]): Bounding box top, left, height, width.\n",
    "            Will be converted into integers for display.\n",
    "\n",
    "            color (str): Color of bounding box in hex (#aaaaaa format)\n",
    "            frame: cv2 loaded frame to annotate\n",
    "        \"\"\"\n",
    "        color = ImageColor.getcolor(color, \"RGB\")[::-1]\n",
    "        top, left, height, width = map(int, bounding_box.values())\n",
    "        cv2.rectangle(\n",
    "            frame,\n",
    "            (left, top),\n",
    "            (left + width, top + height),\n",
    "            color,\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            object_name,\n",
    "            org=(left + 7, top + 16),\n",
    "            fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "            fontScale=1,\n",
    "            color=color,\n",
    "        )\n",
    "\n",
    "    def _draw_intent(self, intent: str, frame) -> None:\n",
    "        \"\"\"Draws text on upper left of frame.\n",
    "\n",
    "        Args:\n",
    "            intent (str): Text to annotate\n",
    "            frame: cv2 loaded frame to annotate\n",
    "        \"\"\"\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            intent,\n",
    "            org=(30, 30),\n",
    "            fontFace=cv2.FONT_HERSHEY_PLAIN,\n",
    "            fontScale=2,\n",
    "            color=(0, 0, 0),\n",
    "        )\n",
    "\n",
    "    def _draw_gaze(\n",
    "        self, head_bounding_box: tuple[float], gaze_bounding_box, frame\n",
    "    ) -> None:\n",
    "        \"\"\"Draws a line between the center point of two bounding boxes.\n",
    "\n",
    "        Args:\n",
    "            head_bounding_box (`tuple[float]`):\n",
    "            Bounding box top, left, height, width of first subject.\n",
    "            Will be converted into integers for display.\n",
    "\n",
    "            gaze_bounding_box:\n",
    "            Bounding box top, left, height, width of second subject.\n",
    "            Will be converted into integers for display.\n",
    "\n",
    "            frame:\n",
    "            Frame loaded in cv2 to annotate\n",
    "        \"\"\"\n",
    "        top, left, height, width = map(int, head_bounding_box.values())\n",
    "        head_center = (left + (width // 2), top + (height // 2))\n",
    "\n",
    "        top, left, height, width = map(int, gaze_bounding_box.values())\n",
    "        gaze_center = (left + (width // 2), top + (height // 2))\n",
    "\n",
    "        cv2.line(frame, head_center, gaze_center, (0, 0, 0), 2)\n",
    "\n",
    "    def annotate(self) -> None:\n",
    "        \"\"\"Draws annotations on loaded video based on annotation ndjson file.\n",
    "\n",
    "        Args:\n",
    "            Display progrss bar. Defaults to False.\n",
    "        \"\"\"\n",
    "\n",
    "        for annotation in tqdm(self._annotations):\n",
    "            successful_read, frame = self._video_capture.read()\n",
    "\n",
    "            self._draw_intent(self._intent, frame)\n",
    "\n",
    "            head_bounding_box, gaze_bounding_box = None, None\n",
    "\n",
    "            for object in annotation[\"objects\"]:\n",
    "                if object[\"classifications\"]:\n",
    "                    gaze_bounding_box = object[\"bbox\"]\n",
    "\n",
    "                if object[\"value\"] == \"head\":\n",
    "                    head_bounding_box = object[\"bbox\"]\n",
    "\n",
    "                self._draw_bounding_box(\n",
    "                    object[\"value\"], object[\"bbox\"], object[\"color\"], frame\n",
    "                )\n",
    "\n",
    "            if gaze_bounding_box is not None:\n",
    "                self._draw_gaze(head_bounding_box, gaze_bounding_box, frame)\n",
    "\n",
    "            frame = cv2.resize(frame, self._display_resolution)\n",
    "            cv2.imshow(\"\", frame)\n",
    "\n",
    "            if self._video_output:\n",
    "                frame = cv2.resize(frame, self._save_resolution)\n",
    "                self._video_output.write(frame)\n",
    "\n",
    "            escape_key = 27\n",
    "            if cv2.waitKey(delay=30) & 0xFF == escape_key:\n",
    "                break\n",
    "\n",
    "    def release(self):\n",
    "        \"\"\"Releases video capture, video writer, and windows.\n",
    "        Call after annotation or for next annotation to free resources.\n",
    "        \"\"\"\n",
    "\n",
    "        if self._video_capture is not None:\n",
    "            self._video_capture.release()\n",
    "            self._video_capture = None\n",
    "\n",
    "        if self._video_output is not None:\n",
    "            self._video_output.release()\n",
    "            self._video_output = None\n",
    "\n",
    "        self._annotations = None\n",
    "        self._intent = None\n",
    "\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "Set the input video and annotation filepath, the save location of the output video file with annotations, and the display and save resolutions of the video during the annotation process (resize either accordingly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_filepath = f\"./data/input.ndjson\"\n",
    "video_filepath = f\"./data/input.mp4\"\n",
    "output_filepath = \"./data/output.mp4\"\n",
    "\n",
    "display_resolution = \"1280x720\"\n",
    "save_resolution = \"1980x1080\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "Loads annotations information, video, and applies annotation for view and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(display_resolution: str, save_resolution: str, annotation_filepath: str, video_filepath: str, output_filepath: str):\n",
    "    display_resolution = tuple(map(int, display_resolution.split(\"x\")))\n",
    "    save_resolution = tuple(map(int, save_resolution.split(\"x\")))\n",
    "\n",
    "    annotator = Annotator()\n",
    "\n",
    "    try:\n",
    "        annotator.load_annotation(annotation_filepath)\n",
    "        annotator.load_video(video_filepath, display_resolution)\n",
    "        annotator.load_output_saver(output_filepath, save_resolution)\n",
    "\n",
    "        annotator.annotate()\n",
    "\n",
    "    finally:\n",
    "        annotator.release()\n",
    "\n",
    "main(display_resolution, save_resolution, annotation_filepath, video_filepath, output_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
